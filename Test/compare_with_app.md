# 머신러닝 모델 비교 결과 리포트

## 실행된 모델
- **Linear Regression**: 일반 최소제곱법(OLS)을 사용한 선형 회귀
- **Lasso**: L1 정규화를 사용한 선형 회귀 (alpha=1.0)
- **Ridge**: L2 정규화를 사용한 선형 회귀 (alpha=1.0)
- **ElasticNet**: L1과 L2 정규화를 결합한 선형 회귀 (alpha=1.0, l1_ratio=0.5)

## 데이터 정보
- **데이터셋**: compactiv.csv
- **총 샘플 수**: 8,192개
- **특성 변수**: 21개 (x1 ~ x21)
- **타겟 변수**: y
- **훈련 데이터**: 5,734개 (70%)
- **테스트 데이터**: 2,458개 (30%)
- **랜덤 시드**: 42

## 모델 성능 비교

### 성능 지표 요약

| 모델 | 훈련 R² | 테스트 R² | 훈련 RMSE | 테스트 RMSE | 훈련 MSE | 테스트 MSE |
|------|---------|-----------|-----------|-------------|----------|------------|
| **LinearRegression** | 0.7258 | **0.7337** | 9.5394 | **9.7136** | 91.00 | 94.35 |
| **Lasso** | 0.7215 | 0.7276 | 9.6135 | 9.8238 | 92.42 | 96.51 |
| **Ridge** | 0.7258 | 0.7337 | 9.5394 | 9.7136 | 91.00 | 94.35 |
| **ElasticNet** | 0.7231 | 0.7295 | 9.5861 | 9.7899 | 91.89 | 95.84 |

### 주요 발견사항

1. **최고 성능 모델**: **LinearRegression**과 **Ridge**가 동일한 성능을 보임
   - 테스트 R²: 0.7337
   - 테스트 RMSE: 9.7136

2. **정규화 효과**: 
   - Ridge는 LinearRegression과 거의 동일한 결과를 보임 (alpha=1.0에서 정규화 효과가 미미)
   - Lasso는 일부 특성의 계수를 0으로 만듦 (x6, x16)
   - ElasticNet은 Lasso와 Ridge의 중간 성능

3. **과적합 여부**: 
   - 모든 모델에서 테스트 R²가 훈련 R²보다 높거나 비슷함 (과적합 없음)
   - 테스트 RMSE가 훈련 RMSE보다 약간 높음 (정상 범위)

## 모델별 상세 결과

### 1. Linear Regression
- **절편 (Intercept)**: 65.3336
- **주요 계수**:
  - x1: -0.0183
  - x2: 0.0015
  - x3: -0.0002
  - x4: 0.0020
  - x5: -0.0035
  - x6: -1.5027 (가장 큰 음의 영향)
  - x10: -0.3683
  - x11: 0.1864
  - x21: 0.00002 (매우 작은 양의 영향)

### 2. Lasso
- **절편 (Intercept)**: 65.7507
- **특징**: 
  - x6과 x16의 계수가 0으로 축소됨 (특성 선택 효과)
  - 다른 계수들도 일부 축소됨
- **주요 계수**:
  - x1: -0.0169
  - x2: 0.0025
  - x3: -0.0001
  - x4: 0.0036
  - x5: -0.0058
  - x6: 0.0 (제거됨)
  - x16: 0.0 (제거됨)

### 3. Ridge
- **절편 (Intercept)**: 65.3340
- **특징**: LinearRegression과 거의 동일한 결과
- **주요 계수**: LinearRegression과 거의 동일

### 4. ElasticNet
- **절편 (Intercept)**: 65.8930
- **특징**: Lasso와 Ridge의 중간 성격
- **주요 계수**: Lasso보다 덜 축소되지만, LinearRegression보다는 축소됨

## 앱에서 결과 확인 방법

### 1. 앱에서 동일한 모델 실행하기

1. **데이터 로드**
   - `LoadData` 모듈을 사용하여 `utils/Test/compactiv.csv` 파일 로드

2. **데이터 분할** (선택사항)
   - `SplitData` 모듈을 사용하여 훈련/테스트 데이터 분할
   - 또는 전체 데이터로 훈련 가능

3. **모델 생성 및 훈련**
   - `LinearRegression` 모듈 생성
   - 파라미터 설정:
     - `model_type`: 'LinearRegression', 'Lasso', 'Ridge', 또는 'ElasticNet'
     - `fit_intercept`: True
     - `alpha`: 1.0 (Lasso, Ridge, ElasticNet의 경우)
     - `l1_ratio`: 0.5 (ElasticNet의 경우)
   - `feature_columns`: ['x1', 'x2', ..., 'x21']
   - `label_column`: 'y'
   - `TrainModel` 모듈로 모델 훈련

4. **결과 확인**
   - 훈련된 모델의 결과는 `TrainedModelPreviewModal`에서 확인 가능
   - 표시되는 정보:
     - Intercept (절편)
     - Coefficients (각 특성의 계수)
     - Metrics (R², MSE, RMSE 등)

### 2. 결과 비교 포인트

앱에서 실행한 결과와 이 스크립트의 결과를 비교할 때 확인할 사항:

1. **절편 (Intercept)**: 동일한 값인지 확인
2. **계수 (Coefficients)**: 각 특성의 계수가 동일한지 확인
3. **성능 지표**: R², MSE, RMSE 값 비교
4. **데이터 분할**: 동일한 random_state(42)와 train_size(0.7) 사용 여부 확인

### 3. 예상되는 차이점

- **앱에서 전체 데이터로 훈련한 경우**: 이 스크립트는 훈련/테스트 분할을 사용하므로 계수 값이 약간 다를 수 있음
- **데이터 전처리**: 앱에서 결측치 처리나 정규화를 수행한 경우 결과가 다를 수 있음
- **수치 정밀도**: JavaScript와 Python의 부동소수점 연산 차이로 인해 매우 작은 차이가 있을 수 있음

## 결론

1. **LinearRegression**과 **Ridge**가 가장 좋은 성능을 보임
2. 이 데이터셋에서는 정규화의 효과가 크지 않음 (alpha=1.0 기준)
3. Lasso는 특성 선택 효과를 보여주지만 성능은 약간 낮음
4. 모든 모델이 과적합 없이 안정적인 성능을 보임

## 참고 파일

- **결과 JSON 파일**: `model_comparison_results.json`
- **실행 스크립트**: `compare_models.py`
- **원본 데이터**: `compactiv.csv`

